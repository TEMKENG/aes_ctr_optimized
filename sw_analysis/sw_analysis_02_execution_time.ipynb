{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software Analysis - 02 - Execution Time\n",
    "\n",
    "''Time is money!'' - that is especially true for applications where performance is a valuable property, e.g. if costs of cloud computation resources matter or if a software should run on the smallest/cheapest possible hardware platform. In these cases, it might be necessary to optimize the execution time of an application.\n",
    "\n",
    "In the following, the analysis and optimization of an application's execution time is explained.\n",
    "\n",
    "Shell command calls are handled by the Python module ``subprocess`` (https://docs.python.org/3/library/subprocess.html).\n",
    "\n",
    "And shell output can be filtered by regular expressions with the Python module ``re`` (https://docs.python.org/3/library/re.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Execution Time with ``time``\n",
    "\n",
    "The Linux command line tool ``time``, specifically ``/usr/bin/time``, can be used to get a simple time measurement for the whole execution of a binary. The option ``-v`` outputs all available information. In the following examples, ``sleep 1`` is used as a test binary that waits for 1 second without much processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = subprocess.run(['/usr/bin/time', '-v', 'sleep', '1'], cwd='./', capture_output=True, text=True)\n",
    "print(time.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of ``time`` can also be formatted by the ``--format`` option. For details, see https://linux.die.net/man/1/time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = subprocess.run(['/usr/bin/time', '--format=REAL: %e  KERNEL: %S  USER: %U', 'sleep', '1'], cwd='./', capture_output=True, text=True)\n",
    "print(time.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Execution Time with ``perf``\n",
    "\n",
    "The tool ``perf`` (https://perf.wiki.kernel.org) is a powerful choice for binary execution time analysis.\n",
    "\n",
    "To enable ``perf`` one has to enable access to performance counter events in Linux (with ``root`` privileges):\n",
    "\n",
    "``echo 0 > /proc/sys/kernel/perf_event_paranoid``\n",
    "\n",
    "Of course, this can also be done outside of this Jupyter notebook in your shell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "sudo_password = 'rustlearner'\n",
    "echo_command = 'sudo -S sh -c \\'echo 0 > /proc/sys/kernel/perf_event_paranoid\\''\n",
    "os.system('echo ' + sudo_password + ' | ' + echo_command)\n",
    "\n",
    "cat = subprocess.run(['cat', '/proc/sys/kernel/perf_event_paranoid'], cwd='./', capture_output=True, text=True)\n",
    "print('perf_event_paranoid =', cat.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic information about the execution of a program can be obtained by calling it with ``perf stat``.\n",
    "\n",
    "The following example measures the command ``sleep 1``.\n",
    "\n",
    "Note that some performance counter values might be ``<not supported>`` within virtual machines or special processor platforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = subprocess.run(['perf', 'stat', 'sleep', '1'], cwd='./', capture_output=True, text=True)\n",
    "print(perf.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rgular expressions might be useful to filter the output of ``perf stat``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = subprocess.run(['perf', 'stat', 'sleep', '1'], cwd='./', capture_output=True, text=True)\n",
    "print('ELAPSED SECONDS:', re.search('([0-9]*,[0-9]*).seconds.time', perf.stderr).group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Time Measurements\n",
    "\n",
    "Keep in mind that every time measurement will have some noise involved, e.g. originating from operating system processes, I/O behavior, or hardware peculiarities.\n",
    "\n",
    "If one measures the same tool several times, one might get several slightly different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    perf = subprocess.run(['perf', 'stat', 'sleep', '1'], cwd='./', capture_output=True, text=True)\n",
    "    print('TRY', i, ':', re.search('([0-9]*,[0-9]*).seconds.time', perf.stderr).group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, it is reasonable to perform several time measurements and present the results in a distribution plot.\n",
    "\n",
    "The plotting of distributions can be achieved with ``matplotlib``, while the module ``tqdm`` is able to provide a progress bar during the measurement process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, the (useless) operation ``dd if=/dev/urandom of=/dev/null bs=16M count=1`` is measured, that moves 16 megabytes of random data into ``/dev/null``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_measurements = 8*8\n",
    "time_data = []\n",
    "for i in tqdm(range(n_measurements)):\n",
    "    perf = subprocess.run(['perf', 'stat', 'dd', 'if=/dev/urandom', 'of=/dev/null', 'bs=16M', 'count=1'], cwd='./', capture_output=True, text=True)\n",
    "    time_str = re.sub(',', '.', re.search('([0-9]*,[0-9]*).seconds.time', perf.stderr).group(1))\n",
    "    time_data.append(float(time_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the collected time data, the average, the min and max values and the distribution of all values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ALL MEASURED EXECUTION TIMES:')\n",
    "for i in range(n_measurements//8):\n",
    "    for j in range(8):\n",
    "        print('{:03.5f}'.format(time_data[i*8+j]), end = ' ')\n",
    "    print('')\n",
    "print('')\n",
    "\n",
    "print('AVERAGE EXECUTION TIME:', end=' ')\n",
    "print('{:03.6f}'.format((sum(time_data)/len(time_data))))\n",
    "\n",
    "print('MINIMUM EXECUTION TIME:', end=' ')\n",
    "print('{:03.6f}'.format(min(time_data)))\n",
    "\n",
    "print('MAXIMUM EXECUTION TIME:', end=' ')\n",
    "print('{:03.6f}'.format(max(time_data)))\n",
    "\n",
    "plt.hist(time_data, bins=32)\n",
    "plt.xlabel('time / s')\n",
    "plt.ylabel('frequency of occurence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Prime Checking Applications in Rust\n",
    "\n",
    "Checking numbers for primality is a common algorithm implementation case that leaves a lot of space for optimizations.\n",
    "\n",
    "This exercise uses different versions of a command line tool for prime checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prime_check_tools = [\n",
    "    'prime_check_lookup_table',\n",
    "    'prime_check_dyngen_table',\n",
    "    'prime_check_no_table',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compile all versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('### Compiling Prime Check Tools ###')\n",
    "for tool in prime_check_tools:\n",
    "  cargo = subprocess.run(['cargo', 'build', '--release'], cwd='./' + tool + '/')\n",
    "  print('Compiling', '{:<24}'.format(tool), '--> Return Code:', cargo.returncode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Time Analysis with 1 Request\n",
    "\n",
    "In the following, all implementations are tested for their execution time when issuing one single prime checking request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_to_check = ['1', '2', '11', '111', '1111', '11111', '111111', '999983']\n",
    "time_data = [[] for tool in prime_check_tools]\n",
    "\n",
    "for t in range(len(prime_check_tools)):\n",
    "    tool = prime_check_tools[t]\n",
    "    for n in tqdm(range(len(numbers_to_check))):\n",
    "        perf = subprocess.run(['perf', 'stat', './' + tool, numbers_to_check[n]],\n",
    "                              cwd='./' + tool + '/target/release/', capture_output=True, text=True)\n",
    "        time_str = re.sub(',', '.', re.search('([0-9]*,[0-9]*).seconds.time', perf.stderr).group(1))\n",
    "        time_data[t].append(float(time_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the distributions and print the relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax_colors = ['brown', 'goldenrod', 'teal']\n",
    "\n",
    "for t in range(len(prime_check_tools)):\n",
    "    tool = prime_check_tools[t]\n",
    "    ax = axs[t]\n",
    "    \n",
    "    # plot distribution\n",
    "    ax.set_title(tool)\n",
    "    ax.xaxis.set_major_formatter(FormatStrFormatter('%.2e'))\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(4))\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "    ax.hist(time_data[t], bins=16, color=ax_colors[t])\n",
    "    ax.set_xlabel('time / s')\n",
    "    ax.set_ylabel('frequency of occurence')\n",
    "    \n",
    "    # print data\n",
    "    print('###', tool, '###')\n",
    "    print('AVG:', '{:03.6f}'.format((sum(time_data[t])/len(time_data[t]))), end=' ')\n",
    "    print('MIN:', '{:03.6f}'.format(min(time_data[t])), end=' ')\n",
    "    print('MAX:', '{:03.6f}'.format(max(time_data[t])))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Time Analysis with a High Number of Requests\n",
    "\n",
    "It is interesting to analyze, if the provided tools behave differently regarding performance and efficiency when fed with a high number of numbers to check for primality.\n",
    "\n",
    "For such testing purposes, the module ``random`` (https://docs.python.org/3/library/random.html) can be useful to generate random test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the provided tools take numbers as command line arguments, one has to care about the maximum size of the shell string. On many Linux systems, it is only possible to pass 128 x 1024 = 131072 characters to the shell. Assuming 6 characters per number plus one space, one can probably check only about 131072 / 7 = 18724 numbers with a single call.\n",
    "\n",
    "Therefore, in the following, all implementations are tested for their execution time when confronted with a near-maximum number of requests (18700).\n",
    "\n",
    "The 18700 numbers to check are randomly choosen from the range between 0 and 999999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_measurements = 8\n",
    "n_numbers = 18700\n",
    "numbers_to_check = [random.sample(range(1000000), n_numbers) for n in range(n_measurements)]\n",
    "time_data = [[] for tool in prime_check_tools]\n",
    "\n",
    "for t in range(len(prime_check_tools)):\n",
    "    tool = prime_check_tools[t]\n",
    "    for n in tqdm(range(n_measurements)):\n",
    "        perf = subprocess.run(['perf', 'stat', './' + tool] + [str(x) for x in numbers_to_check[n]],\n",
    "                              cwd='./' + tool + '/target/release/', capture_output=True, text=True)\n",
    "        time_str = re.sub(',', '.', re.search('([0-9]*,[0-9]*).seconds.time', perf.stderr).group(1))\n",
    "        time_data[t].append(float(time_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code generates the plots and relevant numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(prime_check_tools), figsize=(15, 5))\n",
    "ax_colors = ['brown', 'goldenrod', 'teal']\n",
    "\n",
    "for t in range(len(prime_check_tools)):\n",
    "    tool = prime_check_tools[t]\n",
    "    ax = axs[t]\n",
    "    \n",
    "    # plot distribution\n",
    "    ax.set_title(tool)\n",
    "    ax.xaxis.set_major_formatter(FormatStrFormatter('%.2e'))\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(4))\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "    ax.hist(time_data[t], bins=16, color=ax_colors[t])\n",
    "    ax.set_xlabel('time / s')\n",
    "    ax.set_ylabel('frequency of occurence')\n",
    "    \n",
    "    # print data\n",
    "    print('###', tool, '###')\n",
    "    print('AVG:', '{:03.6f}'.format((sum(time_data[t])/len(time_data[t]))), end=' ')\n",
    "    print('MIN:', '{:03.6f}'.format(min(time_data[t])), end=' ')\n",
    "    print('MAX:', '{:03.6f}'.format(max(time_data[t])))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
